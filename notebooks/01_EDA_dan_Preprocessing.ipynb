{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sel 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Mengatur agar plot matplotlib tampil inline di notebook\n",
    "%matplotlib inline\n",
    "# Mengatur style plot seaborn\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaec1d3",
   "metadata": {},
   "source": [
    "# Sel 2: Markdown\n",
    "# 1. Memuat Data\n",
    "\n",
    "Memuat dataset `heart_failure_clinical_records.csv` dari folder `data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712502ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sel 3: Memuat Data\n",
    "# Path ke dataset. '../' berarti 'naik satu level' dari folder 'notebooks/' ke 'data/'\n",
    "file_path = '../data/heart_failure_clinical_records.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Tampilkan 5 baris pertama untuk verifikasi\n",
    "print(\"Data berhasil dimuat. 5 baris pertama:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0ea9b0",
   "metadata": {},
   "source": [
    "# Sel 4: Markdown\n",
    "# 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Melakukan analisis awal untuk memahami data, sesuai dengan rencana di proposal (Bab 3.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sel 5: EDA - Verifikasi Data\n",
    "print(\"Informasi Dataset (Tipe Data & Nilai Non-Null):\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nRingkasan Statistik Fitur Numerik:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079659aa",
   "metadata": {},
   "source": [
    "# Sel 6: Markdown\n",
    "### 2.1. Analisis Variabel Target (DEATH_EVENT)\n",
    "\n",
    "Menganalisis distribusi kelas target untuk melihat ketidakseimbangan (imbalance) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53a02a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sel 7: EDA - Analisis Target\n",
    "print(\"Distribusi Kelas Target (DEATH_EVENT):\")\n",
    "print(df['DEATH_EVENT'].value_counts())\n",
    "\n",
    "# Visualisasi\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='DEATH_EVENT', data=df)\n",
    "plt.title('Distribusi Kelas Target (0=Selamat, 1=Meninggal)')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservasi: Data tidak seimbang (imbalanced), sesuai proposal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8f6a55",
   "metadata": {},
   "source": [
    "# Sel 8: Markdown\n",
    "### 2.2. Analisis Fitur\n",
    "\n",
    "Melihat distribusi dari fitur-fitur numerik dan kategorikal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e3c1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sel 9: EDA - Distribusi Fitur Numerik\n",
    "# Kita pisahkan fitur biner/kategorikal agar histogram lebih bermakna\n",
    "binary_features = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']\n",
    "numeric_features = [col for col in df.columns if col not in binary_features + ['DEATH_EVENT']]\n",
    "\n",
    "# Plot histogram untuk fitur numerik\n",
    "df[numeric_features].hist(bins=20, figsize=(15, 10))\n",
    "plt.suptitle('Distribusi Fitur Numerik', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b756492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sel 10: EDA - Distribusi Fitur Biner\n",
    "# Plot countplot untuk fitur biner\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(binary_features):\n",
    "    sns.countplot(x=col, data=df, hue='DEATH_EVENT', ax=axes[i])\n",
    "    axes[i].set_title(f'Distribusi Fitur {col}')\n",
    "\n",
    "# Menghapus subplot ekstra jika ada\n",
    "if len(binary_features) < len(axes):\n",
    "    for j in range(len(binary_features), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444f76db",
   "metadata": {},
   "source": [
    "# Sel 11: Markdown\n",
    "### 2.3. Analisis Korelasi (Heatmap)\n",
    "\n",
    "Membuat heatmap korelasi untuk melihat hubungan antar semua fitur. Ini adalah salah satu visualisasi yang direncanakan di proposal (Bab 3.4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d3dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sel 12: EDA - Heatmap Korelasi\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Heatmap Korelasi Antar Fitur')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c00ded",
   "metadata": {},
   "source": [
    "# Sel 13: Markdown\n",
    "# 3. Preprocessing Data\n",
    "\n",
    "Mempersiapkan data untuk modeling:\n",
    "1.  Memisahkan fitur (X) dan target (y).\n",
    "2.  Melakukan Train-Test Split (proporsi 80-20 dan *stratified*).\n",
    "3.  Melakukan Feature Scaling (StandardScaler) pada data training dan testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0634db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sel 14: Preprocessing - Memisahkan X dan y\n",
    "X = df.drop('DEATH_EVENT', axis=1)\n",
    "y = df['DEATH_EVENT']\n",
    "\n",
    "print(\"Bentuk X (fitur):\", X.shape)\n",
    "print(\"Bentuk y (target):\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d3026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sel 15: Preprocessing - Train-Test Split\n",
    "# Melakukan split 80% training dan 20% testing\n",
    "# stratify=y sangat PENTING untuk memastikan proporsi kelas target tetap sama\n",
    "# di data train dan test, karena data kita imbalanced.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,  # random_state untuk hasil yang konsisten\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Bentuk X_train:\", X_train.shape)\n",
    "print(\"Bentuk X_test:\", X_test.shape)\n",
    "print(\"\\nDistribusi target di y_train:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nDistribusi target di y_test:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf073c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sel 16: Preprocessing - Feature Scaling\n",
    "# Logistic Regression sensitif terhadap skala fitur.\n",
    "# Kita wajib melakukan scaling.\n",
    "\n",
    "# 1. Buat scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 2. Fit scaler HANYA pada data training (X_train)\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# 3. Transformasi X_train dan X_test\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Ubah kembali menjadi DataFrame agar mudah dibaca dan disimpan\n",
    "# (Penting: gunakan 'columns=X.columns' untuk menjaga nama kolom)\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "print(\"Data training setelah scaling (5 baris pertama):\")\n",
    "display(X_train_scaled_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f229e03f",
   "metadata": {},
   "source": [
    "# Sel 17: Markdown\n",
    "# 4. Menyimpan Data yang Telah Diproses\n",
    "\n",
    "Menyimpan data `X_train_scaled`, `X_test_scaled`, `y_train`, dan `y_test` ke folder `data/` agar bisa langsung digunakan oleh Notebook `02_Modeling_Logistic_Regression.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sel 18: Menyimpan Data\n",
    "# Tentukan path penyimpanan\n",
    "path_prefix = '../data/'\n",
    "\n",
    "# Simpan data yang sudah bersih dan terpisah\n",
    "X_train_scaled_df.to_csv(path_prefix + 'X_train_scaled.csv', index=False)\n",
    "X_test_scaled_df.to_csv(path_prefix + 'X_test_scaled.csv', index=False)\n",
    "y_train.to_csv(path_prefix + 'y_train.csv', index=False)\n",
    "y_test.to_csv(path_prefix + 'y_test.csv', index=False)\n",
    "\n",
    "print(\"Data telah diproses dan disimpan di folder 'data/':\")\n",
    "print(f\"- X_train_scaled.csv ({X_train_scaled_df.shape})\")\n",
    "print(f\"- X_test_scaled.csv ({X_test_scaled_df.shape})\")\n",
    "print(f\"- y_train.csv ({y_train.shape})\")\n",
    "print(f\"- y_test.csv ({y_test.shape})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3efaab",
   "metadata": {},
   "source": [
    "# Sel 19: Markdown\n",
    "# Selesai\n",
    "\n",
    "EDA dan Preprocessing telah selesai. Data bersih siap untuk modeling di notebook `02_Modeling_Logistic_Regression.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
